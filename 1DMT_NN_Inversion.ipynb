{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "97825819-c6d7-4919-9841-46cd0430d23f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Loss: 1.7091\n",
      "Epoch [2/100], Loss: 1.7064\n",
      "Epoch [3/100], Loss: 1.0668\n",
      "Epoch [4/100], Loss: 1.1784\n",
      "Epoch [5/100], Loss: 1.7338\n",
      "Epoch [6/100], Loss: 1.1413\n",
      "Epoch [7/100], Loss: 0.9996\n",
      "Epoch [8/100], Loss: 1.1315\n",
      "Epoch [9/100], Loss: 1.4301\n",
      "Epoch [10/100], Loss: 0.8046\n",
      "Epoch [11/100], Loss: 1.1042\n",
      "Epoch [12/100], Loss: 1.1280\n",
      "Epoch [13/100], Loss: 1.0796\n",
      "Epoch [14/100], Loss: 1.3798\n",
      "Epoch [15/100], Loss: 1.3294\n",
      "Epoch [16/100], Loss: 0.9719\n",
      "Epoch [17/100], Loss: 1.2647\n",
      "Epoch [18/100], Loss: 0.8902\n",
      "Epoch [19/100], Loss: 1.2640\n",
      "Epoch [20/100], Loss: 1.0560\n",
      "Epoch [21/100], Loss: 1.0128\n",
      "Epoch [22/100], Loss: 1.0260\n",
      "Epoch [23/100], Loss: 0.7831\n",
      "Epoch [24/100], Loss: 0.9826\n",
      "Epoch [25/100], Loss: 1.4265\n",
      "Epoch [26/100], Loss: 1.3101\n",
      "Epoch [27/100], Loss: 1.1713\n",
      "Epoch [28/100], Loss: 1.2767\n",
      "Epoch [29/100], Loss: 1.4849\n",
      "Epoch [30/100], Loss: 1.0849\n",
      "Epoch [31/100], Loss: 1.1831\n",
      "Epoch [32/100], Loss: 1.0376\n",
      "Epoch [33/100], Loss: 1.3667\n",
      "Epoch [34/100], Loss: 1.2993\n",
      "Epoch [35/100], Loss: 1.1901\n",
      "Epoch [36/100], Loss: 1.4063\n",
      "Epoch [37/100], Loss: 1.1849\n",
      "Epoch [38/100], Loss: 1.1627\n",
      "Epoch [39/100], Loss: 1.3650\n",
      "Epoch [40/100], Loss: 0.8911\n",
      "Epoch [41/100], Loss: 1.0735\n",
      "Epoch [42/100], Loss: 1.0454\n",
      "Epoch [43/100], Loss: 1.1378\n",
      "Epoch [44/100], Loss: 1.0159\n",
      "Epoch [45/100], Loss: 0.9728\n",
      "Epoch [46/100], Loss: 1.0913\n",
      "Epoch [47/100], Loss: 1.1681\n",
      "Epoch [48/100], Loss: 1.1639\n",
      "Epoch [49/100], Loss: 0.9705\n",
      "Epoch [50/100], Loss: 1.0981\n",
      "Epoch [51/100], Loss: 0.9602\n",
      "Epoch [52/100], Loss: 1.0220\n",
      "Epoch [53/100], Loss: 1.4736\n",
      "Epoch [54/100], Loss: 0.8072\n",
      "Epoch [55/100], Loss: 0.9662\n",
      "Epoch [56/100], Loss: 1.1975\n",
      "Epoch [57/100], Loss: 1.2466\n",
      "Epoch [58/100], Loss: 1.1926\n",
      "Epoch [59/100], Loss: 1.0987\n",
      "Epoch [60/100], Loss: 1.4424\n",
      "Epoch [61/100], Loss: 1.1983\n",
      "Epoch [62/100], Loss: 1.3565\n",
      "Epoch [63/100], Loss: 0.9001\n",
      "Epoch [64/100], Loss: 1.3782\n",
      "Epoch [65/100], Loss: 0.9182\n",
      "Epoch [66/100], Loss: 0.9983\n",
      "Epoch [67/100], Loss: 1.1690\n",
      "Epoch [68/100], Loss: 1.1644\n",
      "Epoch [69/100], Loss: 1.2175\n",
      "Epoch [70/100], Loss: 1.0944\n",
      "Epoch [71/100], Loss: 1.1788\n",
      "Epoch [72/100], Loss: 1.2043\n",
      "Epoch [73/100], Loss: 1.2854\n",
      "Epoch [74/100], Loss: 1.2876\n",
      "Epoch [75/100], Loss: 0.9076\n",
      "Epoch [76/100], Loss: 0.9323\n",
      "Epoch [77/100], Loss: 0.9696\n",
      "Epoch [78/100], Loss: 1.0625\n",
      "Epoch [79/100], Loss: 1.3333\n",
      "Epoch [80/100], Loss: 0.9586\n",
      "Epoch [81/100], Loss: 1.2215\n",
      "Epoch [82/100], Loss: 0.8934\n",
      "Epoch [83/100], Loss: 1.0174\n",
      "Epoch [84/100], Loss: 1.0857\n",
      "Epoch [85/100], Loss: 1.3205\n",
      "Epoch [86/100], Loss: 1.0374\n",
      "Epoch [87/100], Loss: 0.8684\n",
      "Epoch [88/100], Loss: 0.8638\n",
      "Epoch [89/100], Loss: 1.1855\n",
      "Epoch [90/100], Loss: 0.9039\n",
      "Epoch [91/100], Loss: 1.2010\n",
      "Epoch [92/100], Loss: 1.1350\n",
      "Epoch [93/100], Loss: 0.8220\n",
      "Epoch [94/100], Loss: 0.9176\n",
      "Epoch [95/100], Loss: 1.1008\n",
      "Epoch [96/100], Loss: 0.9742\n",
      "Epoch [97/100], Loss: 0.8630\n",
      "Epoch [98/100], Loss: 0.9890\n",
      "Epoch [99/100], Loss: 1.0041\n",
      "Epoch [100/100], Loss: 1.1430\n",
      "--- 385.8617470264435 seconds ---\n",
      "Mean squared error on test set: 1.0771\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.data as data_utils\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import time\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "#Load data tensors\n",
    "input_data = torch.load(r'C:\\Users\\Diana22\\Documents\\Andrew\\Houston Geophysics\\SimPEG\\simpeg\\SimPEG\\electromagnetics\\natural_source\\input_data.pt')\n",
    "target_data = torch.load(r'C:\\Users\\Diana22\\Documents\\Andrew\\Houston Geophysics\\SimPEG\\simpeg\\SimPEG\\electromagnetics\\natural_source\\target_data.pt')\n",
    "input_tensor = torch.tensor(input_data, dtype=torch.float32)\n",
    "target_tensor = torch.tensor(target_data, dtype=torch.float32)\n",
    "# Check for NaN values in the input and target tensors\n",
    "if torch.isnan(input_tensor).any() or torch.isnan(target_tensor).any():\n",
    "    print(\"Input or target data contains NaN values.\")\n",
    "\n",
    "#Split data into training and testing sets\n",
    "split_ratio = 0.8\n",
    "split = int(len(input_tensor) * split_ratio)\n",
    "train_input = input_tensor[:split]\n",
    "train_target = target_tensor[:split]\n",
    "test_input = input_tensor[split:]\n",
    "test_target = target_tensor[split:]\n",
    "\n",
    "#Create data loaders for training and testing\n",
    "train_dataset = TensorDataset(train_input, train_target)\n",
    "test_dataset = TensorDataset(test_input, test_target)\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "#Build model architecture\n",
    "input_size = 56  #Input dimension\n",
    "hidden_size = 128  #Number of neurons in the hidden layer\n",
    "output_size = 51  #Output dimension\n",
    "model = NeuralNetwork(input_size, hidden_size, output_size)\n",
    "criterion = nn.MSELoss()  # Mean Squared Error\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.0001)  # Stochastic Gradient Descent\n",
    "\n",
    "#Run Model\n",
    "start_time = time.time()\n",
    "num_epochs = 100\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in train_loader:\n",
    "        #Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        #Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    #if (epoch + 1) % 10 == 0:\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))    \n",
    "\n",
    "#Evaluate model on test dataset\n",
    "model.eval()\n",
    "total_loss = 0.0\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        total_loss += loss.item()\n",
    "mean_loss = total_loss / len(test_loader)\n",
    "print(f\"Mean squared error on test set: {mean_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5641c8c-0aeb-4d56-8134-cb30b8dac91b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
